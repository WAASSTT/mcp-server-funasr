"""FunASR MCPæœåŠ¡å™¨ä¸»ç¨‹åº v4.0.0

åŸºäºFastMCPæ¡†æ¶æä¾›ä¸“ä¸šçš„ä¸­æ–‡è¯­éŸ³è¯†åˆ«æœåŠ¡:
- å®æ—¶æµå¼è¯­éŸ³è¯†åˆ« (Paraformer-Streaming)
- æ‰¹é‡è¯­éŸ³è¯†åˆ« (Paraformer-large + VADåˆ†æ®µ + æ ‡ç‚¹æ¢å¤ + è¯´è¯äººåˆ†ç¦»)
- LLMæµå¼åå¤„ç† (GGUFé‡åŒ–æ¨¡å‹ï¼ŒCPUå‹å¥½)
- çƒ­è¯å®šåˆ¶æ”¯æŒ
- å¤šå®¢æˆ·ç«¯å¹¶å‘æ”¯æŒ

ç‰ˆæœ¬: 4.0.0
æ›´æ–°æ—¥æœŸ: 2025-12-23
"""

import os
import tempfile
import json
import asyncio
import threading
import uuid
import logging
import signal
import sys
from datetime import datetime
from typing import Dict, Any

# è®¾ç½®æ¨¡å‹ç¼“å­˜åˆ°é¡¹ç›®ç›®å½• (å¿…é¡»åœ¨å¯¼å…¥funasrä¹‹å‰)
os.environ["MODELSCOPE_CACHE"] = "./Model"

import numpy as np
from fastmcp import FastMCP
from core.realtime_transcriber import RealtimeTranscriber
from core.batch_transcriber import BatchTranscriber
from core.device_utils import detect_device
from starlette.middleware import Middleware
from starlette.middleware.cors import CORSMiddleware
from starlette.responses import JSONResponse
from starlette.requests import Request
from starlette.websockets import WebSocket, WebSocketDisconnect

# ========== é…ç½® ==========


class Config:
    """æœåŠ¡å™¨é…ç½®"""

    # æœåŠ¡å™¨é…ç½®
    SERVER_HOST = "0.0.0.0"
    SERVER_PORT = 8000
    TIMEOUT_KEEP_ALIVE = 75
    TIMEOUT_GRACEFUL_SHUTDOWN = 30

    # æ¨¡å‹é…ç½®
    MODEL_CACHE_DIR = "./Model"

    # å®æ—¶è¯†åˆ«é…ç½®
    REALTIME_MODEL = "paraformer-zh-streaming"
    REALTIME_CHUNK_SIZE = [0, 10, 5]  # 600mså»¶è¿Ÿ
    REALTIME_NCPU = 4

    # æ‰¹é‡è¯†åˆ«é…ç½®
    BATCH_MODEL = "paraformer-zh"
    BATCH_VAD_MODEL = "fsmn-vad"
    BATCH_PUNC_MODEL = "ct-punc-c"
    BATCH_SPK_MODEL = "cam++"
    BATCH_NCPU = 4
    BATCH_SIZE_S = 300
    BATCH_HOTWORD = "é­”æ­"

    # æµå¼åå¤„ç†é…ç½®ï¼ˆGGUFæ ¼å¼ï¼‰- ååŒè®¾è®¡ï¼šASRå¬æ¸… + LLMè¯´äººè¯
    ENABLE_POSTPROCESSOR = True
    POSTPROCESSOR_MODEL_PATH = "./Model/models/Qwen/qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf"
    POSTPROCESSOR_TEMPERATURE = 0.3
    POSTPROCESSOR_N_GPU_LAYERS = None  # None=è‡ªåŠ¨æ£€æµ‹
    POSTPROCESSOR_CONTEXT_WINDOW = 3   # ä¸Šä¸‹æ–‡çª—å£å¤§å°
    POSTPROCESSOR_MIN_BUFFER = 2       # æœ€å°ç¼“å†²åŒºå¤§å°
    POSTPROCESSOR_MAX_BUFFER = 5       # æœ€å¤§ç¼“å†²åŒºå¤§å°
    POSTPROCESSOR_QUALITY_CHECK = True # å¯ç”¨è´¨é‡æ£€æŸ¥

    # WebSocketé…ç½®
    WS_CHUNK_SIZE_MS = 600
    WS_MAX_BUFFER_SIZE_CHUNKS = 3
    WS_MAX_BUFFER_BYTES = 64000
    WS_LOCK_TIMEOUT = 5.0


# ========== æ—¥å¿—é…ç½® ==========

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# ========== å…¨å±€å˜é‡ ==========

# FastMCPæœåŠ¡å™¨
mcp = FastMCP(name="FunASRè¯­éŸ³æœåŠ¡")

# å¹¶å‘æ§åˆ¶
realtime_model_lock = threading.Lock()
batch_model_lock = threading.Lock()
connection_lock = threading.Lock()

# è¿æ¥ç®¡ç†
active_connections: Dict[str, Dict[str, Any]] = {}
connection_counter = 0


# ========== æ¨¡å‹åˆå§‹åŒ– ==========


def init_models() -> tuple[RealtimeTranscriber, BatchTranscriber]:
    """åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«æ¨¡å‹"""
    # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
    device = detect_device()
    logger.info(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {device.upper()}")
    logger.info(f"âœ¨ LLMåå¤„ç†: å·²å¯ç”¨ (GGUFæ¨¡å‹)")

    # å®æ—¶è¯†åˆ«å™¨
    realtime = RealtimeTranscriber(
        model=Config.REALTIME_MODEL,
        device=device,
        ncpu=Config.REALTIME_NCPU,
        chunk_size=Config.REALTIME_CHUNK_SIZE,
        encoder_chunk_look_back=4,
        decoder_chunk_look_back=1,
        model_hub="ms",
        enable_llm_postprocess=Config.ENABLE_POSTPROCESSOR,
        llm_model_path=Config.POSTPROCESSOR_MODEL_PATH,
        llm_temperature=Config.POSTPROCESSOR_TEMPERATURE,
        llm_n_gpu_layers=Config.POSTPROCESSOR_N_GPU_LAYERS,
    )

    # æ‰¹é‡è¯†åˆ«å™¨
    batch = BatchTranscriber(
        model=Config.BATCH_MODEL,
        vad_model=Config.BATCH_VAD_MODEL,
        punc_model=Config.BATCH_PUNC_MODEL,
        spk_model=Config.BATCH_SPK_MODEL,
        device=device,
        ncpu=Config.BATCH_NCPU,
        vad_kwargs={"max_single_segment_time": 30000},
        batch_size_s=Config.BATCH_SIZE_S,
        model_hub="ms",
        hotword=Config.BATCH_HOTWORD,
    )

    return realtime, batch


realtime_transcriber, batch_transcriber = init_models()


# ========== ä¼˜é›…å…³é—­å¤„ç† ==========

def cleanup_resources():
    """æ¸…ç†æ‰€æœ‰èµ„æº"""
    try:
        logger.info("å¼€å§‹æ¸…ç†èµ„æº...")

        # æ¸…ç†å®æ—¶è½¬å½•å™¨
        if hasattr(realtime_transcriber, 'close'):
            realtime_transcriber.close()
            logger.info("å®æ—¶è½¬å½•å™¨å·²å…³é—­")

        # æ¸…ç†æ‰¹é‡è½¬å½•å™¨
        if hasattr(batch_transcriber, 'close'):
            batch_transcriber.close()
            logger.info("æ‰¹é‡è½¬å½•å™¨å·²å…³é—­")

        logger.info("âœ“ èµ„æºæ¸…ç†å®Œæˆ")
    except Exception as e:
        logger.error(f"èµ„æºæ¸…ç†é”™è¯¯: {e}")


def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
    cleanup_resources()
    sys.exit(0)


# æ³¨å†Œä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)


# ========== æ³¨å†ŒMCPå·¥å…· ==========


# ---------- æ‰¹é‡è¯­éŸ³è¯†åˆ«å·¥å…· ----------
@mcp.tool(
    name="transcribe_audio",
    description="å¯¹éŸ³é¢‘æ–‡ä»¶è¿›è¡Œæ‰¹é‡è¯­éŸ³è¯†åˆ«ï¼Œä½¿ç”¨VADåˆ†æ®µåè¿›è¡Œæ‰¹é‡è¯†åˆ«ï¼Œæ”¯æŒçƒ­è¯å®šåˆ¶",
)
def transcribe_audio(
    audio_path: str,
    return_vad_segments: bool = False,
    hotword: str | None = None,
) -> dict:
    """æ‰¹é‡è¯­éŸ³è¯†åˆ«

    ä½¿ç”¨VADè¿›è¡Œè¯­éŸ³åˆ†æ®µï¼Œç„¶åå¯¹æ‰€æœ‰è¯­éŸ³æ®µè¿›è¡Œæ‰¹é‡è¯†åˆ«ã€‚
    é€‚ç”¨äºå®Œæ•´éŸ³é¢‘æ–‡ä»¶çš„ç¦»çº¿å¤„ç†ã€‚

    å‚æ•°:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        return_vad_segments: æ˜¯å¦è¿”å›VADåˆ†æ®µçš„æ—¶é—´æˆ³ä¿¡æ¯
        hotword: çƒ­è¯ï¼Œç”¨äºæé«˜ç‰¹å®šè¯æ±‡çš„è¯†åˆ«å‡†ç¡®ç‡ (ä¾‹: "é­”æ­")

    è¿”å›:
        åŒ…å«è¯†åˆ«ç»“æœçš„å­—å…¸:
        - status: "success" æˆ– "error"
        - text: å®Œæ•´è¯†åˆ«æ–‡æœ¬
        - results: FunASRåŸå§‹ç»“æœåˆ—è¡¨
        - audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        - audio_info: éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
        - vad_segments: VADåˆ†æ®µä¿¡æ¯(å¦‚æœreturn_vad_segments=True)
    """
    # ä½¿ç”¨é”ä¿æŠ¤æ¨¡å‹æ¨ç† (æ”¯æŒå¹¶å‘è°ƒç”¨)
    with batch_model_lock:
        kwargs = {}
        if hotword:
            kwargs["hotword"] = hotword

        if return_vad_segments:
            return batch_transcriber.transcribe_with_vad_segments(
                audio_path=audio_path, return_vad_segments=True, **kwargs
            )
        else:
            return batch_transcriber.transcribe(audio_path=audio_path, **kwargs)


@mcp.tool(
    name="validate_audio_file", description="éªŒè¯éŸ³é¢‘æ–‡ä»¶æ˜¯å¦é€‚åˆå¤„ç†å¹¶æä¾›å…¶å±æ€§ä¿¡æ¯"
)
def validate_audio_file(file_path: str) -> dict:
    """éªŒè¯éŸ³é¢‘æ–‡ä»¶

    æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€å¯è¯»ä¸”ä¸ºæœ‰æ•ˆçš„éŸ³é¢‘æ ¼å¼ã€‚

    å‚æ•°:
        file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    è¿”å›:
        åŒ…å«éªŒè¯çŠ¶æ€ã€æ¶ˆæ¯å’ŒéŸ³é¢‘å±æ€§çš„å­—å…¸
    """
    return batch_transcriber.validate_audio(file_path)


# ========== é…ç½® CORS ä¸­é—´ä»¶ ==========
cors_middleware = [
    Middleware(
        CORSMiddleware,
        allow_origins=["*"],  # å…è®¸æ‰€æœ‰æºï¼Œç”Ÿäº§ç¯å¢ƒåº”é™åˆ¶ä¸ºç‰¹å®šåŸŸå
        allow_methods=["GET", "POST", "DELETE", "OPTIONS"],
        allow_headers=[
            "mcp-protocol-version",
            "mcp-session-id",
            "Authorization",
            "Content-Type",
            "Accept",
            "Cache-Control",
            "X-Requested-With",
        ],
        expose_headers=[
            "mcp-session-id",
            "Content-Type",
        ],
        allow_credentials=True,
        max_age=3600,  # é¢„æ£€è¯·æ±‚ç¼“å­˜1å°æ—¶
    )
]


# ========== éŸ³é¢‘ä¸Šä¼ ç«¯ç‚¹ ==========
async def upload_audio_endpoint(request: Request):
    """æ¥æ”¶æµè§ˆå™¨å½•åˆ¶çš„éŸ³é¢‘å¹¶è¿›è¡Œæ‰¹é‡è¯†åˆ«"""
    try:
        # è¯»å–ä¸Šä¼ çš„éŸ³é¢‘æ•°æ®
        audio_data = await request.body()

        if not audio_data:
            return JSONResponse(
                {"status": "error", "message": "æ²¡æœ‰æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®"}, status_code=400
            )

        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as temp_file:
            temp_file.write(audio_data)
            temp_path = temp_file.name

        try:
            # ä½¿ç”¨æ‰¹é‡è¯†åˆ«å™¨è¿›è¡Œè½¬å½• (ä½¿ç”¨é”ä¿æŠ¤æ¨¡å‹æ¨ç†)
            with batch_model_lock:
                result = batch_transcriber.transcribe(temp_path)
            return JSONResponse({"status": "success", "result": result})
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_path)

    except Exception as e:
        return JSONResponse(
            {"status": "error", "message": f"è½¬å½•å¤±è´¥: {str(e)}"}, status_code=500
        )


# ========== WebSocketå®æ—¶è¯­éŸ³è¯†åˆ«ç«¯ç‚¹ ==========
async def websocket_realtime_endpoint(websocket: WebSocket):
    """WebSocketç«¯ç‚¹ï¼šå®æ—¶æ¥æ”¶éŸ³é¢‘æµå¹¶è¿›è¡Œè¯†åˆ«

    ä½¿ç”¨paraformer-zh-streamingè¿›è¡Œæµå¼è¯†åˆ«:
    - æ¨¡å‹å†…ç½®VADï¼Œè‡ªåŠ¨æ£€æµ‹è¯­éŸ³æ´»åŠ¨
    - chunk_sizeé…ç½®ä¸º[0,10,5]ï¼Œå³600mså®æ—¶ç²’åº¦
    - æ¯æ¬¡è¾“å…¥600mséŸ³é¢‘(9600 samples @ 16kHz)
    - é€šè¿‡cacheç»´æŠ¤æµå¼çŠ¶æ€
    - æ”¯æŒå¤šå®¢æˆ·ç«¯å¹¶å‘ï¼ˆä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤æ¨¡å‹æ¨ç†ï¼‰
    - æ·»åŠ è¶…æ—¶ä¿æŠ¤å’Œèµ„æºç®¡ç†
    - LLMæµå¼åå¤„ç†ï¼ˆååŒè®¾è®¡ï¼‰
    """
    await websocket.accept()

    # ä¸ºæ¯ä¸ªè¿æ¥åˆ†é…å”¯ä¸€ID
    global connection_counter
    with connection_lock:
        connection_counter += 1
        session_id = f"session_{connection_counter}_{uuid.uuid4().hex[:8]}"
        active_connections[session_id] = {
            "start_time": datetime.now(),
            "chunk_count": 0,
            "websocket": websocket,
            "last_activity": datetime.now(),
        }

    print(
        f"[{session_id}] WebSocketå®¢æˆ·ç«¯å·²è¿æ¥ (å½“å‰æ´»è·ƒè¿æ¥: {len(active_connections)})"
    )

    try:
        # å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
        await websocket.send_json(
            {
                "type": "connected",
                "message": "WebSocketè¿æ¥æˆåŠŸï¼Œä½¿ç”¨Paraformeræµå¼æ¨¡å‹",
                "session_id": session_id,
                "active_connections": len(active_connections),
            }
        )

        # ä¼šè¯çº§cache (FunASRæµå¼è¯†åˆ«å¿…éœ€ï¼Œæ¯ä¸ªè¿æ¥ç‹¬ç«‹)
        cache_asr = {}
        chunk_count = 0

        # Bufferç®¡ç† - ä½¿ç”¨å›ºå®šå¤§å°æ•°ç»„é¿å…np.appendæ€§èƒ½é—®é¢˜
        chunk_size = int(Config.WS_CHUNK_SIZE_MS * 16000 / 1000)  # 9600 samples
        max_buffer_size = (
            chunk_size * Config.WS_MAX_BUFFER_SIZE_CHUNKS
        )  # æœ€å¤šç¼“å†²3ä¸ªchunk
        audio_buffer = np.zeros(max_buffer_size, dtype=np.float32)
        buffer_write_index = 0
        buffer_bytes = b""

        while True:
            # æ¥æ”¶æ¶ˆæ¯
            message = await websocket.receive()

            # å¤„ç†æ–‡æœ¬æ¶ˆæ¯ï¼ˆæ§åˆ¶å‘½ä»¤ï¼‰
            if "text" in message:
                data = json.loads(message["text"])

                if data.get("type") == "start":
                    print(f"[{session_id}] æ”¶åˆ°startå‘½ä»¤ï¼Œæ¸…ç©ºç¼“å­˜")
                    cache_asr.clear()
                    chunk_count = 0
                    audio_buffer.fill(0)
                    buffer_write_index = 0
                    buffer_bytes = b""
                    active_connections[session_id]["chunk_count"] = 0

                    # é‡ç½®åå¤„ç†å™¨çŠ¶æ€ï¼ˆååŒè®¾è®¡ï¼šæ–°ä¼šè¯å¼€å§‹ï¼‰
                    try:
                        if realtime_transcriber and hasattr(realtime_transcriber, 'reset_postprocessor'):
                            realtime_transcriber.reset_postprocessor()
                            logger.info(f"[{session_id}] åå¤„ç†å™¨å·²é‡ç½®ï¼ˆæ–°ä¼šè¯å¼€å§‹ï¼‰")
                    except Exception as e:
                        logger.warning(f"[{session_id}] åå¤„ç†å™¨é‡ç½®å¤±è´¥: {e}")

                    await websocket.send_json(
                        {
                            "type": "started",
                            "message": "å¼€å§‹è¯†åˆ«",
                            "session_id": session_id,
                        }
                    )

                elif data.get("type") == "stop":
                    print(
                        f"[{session_id}] æ”¶åˆ°stopå‘½ä»¤ï¼Œæ€»å…±å¤„ç†äº† {chunk_count} ä¸ªéŸ³é¢‘å—"
                    )

                    # å¤„ç†å‰©ä½™çš„éŸ³é¢‘ç¼“å†²åŒº
                    if buffer_write_index > 1600:  # è‡³å°‘100msçš„æ•°æ®
                        try:
                            print(
                                f"[{session_id}] å¤„ç†å‰©ä½™éŸ³é¢‘: {buffer_write_index} æ ·æœ¬"
                            )

                            # ä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤æ¨¡å‹æ¨ç†
                            with realtime_model_lock:
                                result = realtime_transcriber.transcribe_chunk(
                                    audio_chunk=audio_buffer[:buffer_write_index],
                                    cache=cache_asr,
                                    is_final=True,
                                    sample_rate=16000,
                                )

                            if result and result.get("text"):
                                chunk_count += 1
                                print(f"[{session_id}] æœ€ç»ˆè¯†åˆ«ç»“æœ: {result['text']}")
                                await websocket.send_json(
                                    {
                                        "type": "result",
                                        "text": result["text"],
                                        "is_final": True,
                                        "chunk_number": chunk_count,
                                        "session_id": session_id,
                                    }
                                )
                        except Exception as e:
                            print(f"[{session_id}] å¤„ç†å‰©ä½™éŸ³é¢‘å¤±è´¥: {e}")
                            import traceback

                            traceback.print_exc()

                    # æ¸…ç©ºç¼“å­˜
                    cache_asr.clear()
                    audio_buffer.fill(0)
                    buffer_write_index = 0
                    buffer_bytes = b""

                    # ç»“æŸè¯†åˆ«
                    await websocket.send_json(
                        {
                            "type": "stopped",
                            "message": "è¯†åˆ«ç»“æŸ",
                            "total_chunks": chunk_count,
                        }
                    )
                    break

            # å¤„ç†äºŒè¿›åˆ¶æ¶ˆæ¯ï¼ˆéŸ³é¢‘æ•°æ®ï¼‰
            elif "bytes" in message:
                audio_bytes = message["bytes"]
                # print(f"[{session_id}] æ”¶åˆ°éŸ³é¢‘æ•°æ®: {len(audio_bytes)} å­—èŠ‚")  # å¤ªé¢‘ç¹ï¼Œæ³¨é‡Šæ‰

                try:
                    # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
                    if len(audio_bytes) < 2:
                        continue

                    # ç´¯ç§¯å­—èŠ‚æ•°æ®
                    buffer_bytes += audio_bytes

                    # é˜²æ­¢ç¼“å†²åŒºæ— é™å¢é•¿
                    if len(buffer_bytes) > Config.WS_MAX_BUFFER_BYTES:
                        print(
                            f"[{session_id}] âš ï¸ å­—èŠ‚ç¼“å†²åŒºè¿‡å¤§({len(buffer_bytes)}å­—èŠ‚)ï¼Œæ¸…ç†æ—§æ•°æ®"
                        )
                        buffer_bytes = buffer_bytes[-Config.WS_MAX_BUFFER_BYTES :]

                    if len(buffer_bytes) < 2:
                        continue

                    # è½¬æ¢ä¸ºfloat32æ•°ç»„ï¼ˆä»int16ï¼‰
                    num_samples = len(buffer_bytes) - (len(buffer_bytes) % 2)
                    if num_samples > 0:
                        new_samples = (
                            np.frombuffer(
                                buffer_bytes[:num_samples],
                                dtype=np.int16,
                            ).astype(np.float32)
                            / 32768.0
                        )

                        # æ£€æŸ¥ç¼“å†²åŒºç©ºé—´ - æ·»åŠ å®‰å…¨è¾¹ç•Œ
                        if buffer_write_index + len(new_samples) > max_buffer_size:
                            # ç¼“å†²åŒºæ»¡ï¼Œç§»åŠ¨æ•°æ®åˆ°å¼€å¤´
                            remaining = min(
                                buffer_write_index % chunk_size, max_buffer_size // 2
                            )
                            if remaining > 0 and buffer_write_index >= remaining:
                                audio_buffer[:remaining] = audio_buffer[
                                    buffer_write_index - remaining : buffer_write_index
                                ]
                            buffer_write_index = remaining
                            print(
                                f"[{session_id}] ç¼“å†²åŒºå·²æ»¡ï¼Œé‡ç½®ï¼ˆä¿ç•™ {remaining} æ ·æœ¬ï¼‰"
                            )

                        # å†™å…¥æ–°æ•°æ® - ç¡®ä¿ä¸è¶Šç•Œ
                        samples_to_write = min(
                            len(new_samples), max_buffer_size - buffer_write_index
                        )
                        if (
                            samples_to_write > 0
                            and buffer_write_index + samples_to_write <= max_buffer_size
                        ):
                            audio_buffer[
                                buffer_write_index : buffer_write_index
                                + samples_to_write
                            ] = new_samples[:samples_to_write]
                            buffer_write_index += samples_to_write
                        buffer_bytes = buffer_bytes[num_samples:]

                        # print(f"[{session_id}] éŸ³é¢‘ç¼“å†²åŒº: {buffer_write_index} æ ·æœ¬")  # å¤ªé¢‘ç¹

                    # å½“ç¼“å†²åŒºè¾¾åˆ°600msæ—¶è¿›è¡Œæµå¼è¯†åˆ«
                    while buffer_write_index >= chunk_size:
                        chunk = audio_buffer[:chunk_size].copy()
                        # ç§»åŠ¨å‰©ä½™æ•°æ®
                        remaining = buffer_write_index - chunk_size
                        if remaining > 0:
                            audio_buffer[:remaining] = audio_buffer[
                                chunk_size:buffer_write_index
                            ]
                        buffer_write_index = remaining

                        print(
                            f"[{session_id}] å¤„ç†éŸ³é¢‘å— {chunk_count + 1}: {len(chunk)} æ ·æœ¬ ({Config.WS_CHUNK_SIZE_MS}ms)"
                        )

                        try:
                            # Paraformeræµå¼è¯†åˆ« (æ ‡å‡†FunASRæµå¼ç”¨æ³•)
                            # ä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤æ¨¡å‹æ¨ç†ï¼ˆæ”¯æŒå¤šå®¢æˆ·ç«¯å¹¶å‘ï¼‰
                            # æ·»åŠ è¶…æ—¶ä¿æŠ¤é¿å…é•¿æ—¶é—´é˜»å¡
                            lock_acquired = realtime_model_lock.acquire(
                                timeout=Config.WS_LOCK_TIMEOUT
                            )
                            if not lock_acquired:
                                print(f"[{session_id}] âš ï¸ è·å–æ¨¡å‹é”è¶…æ—¶ï¼Œè·³è¿‡æœ¬æ¬¡è¯†åˆ«")
                                continue

                            try:
                                result = realtime_transcriber.transcribe_chunk(
                                    audio_chunk=chunk,
                                    cache=cache_asr,
                                    is_final=False,
                                    sample_rate=16000,
                                )
                            finally:
                                realtime_model_lock.release()

                            # print(f"[{session_id}] è¯†åˆ«ç»“æœ: {result}")  # è°ƒè¯•ç”¨

                            # æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
                            with connection_lock:
                                if session_id in active_connections:
                                    active_connections[session_id][
                                        "last_activity"
                                    ] = datetime.now()

                            if result and result.get("text"):
                                chunk_count += 1
                                active_connections[session_id][
                                    "chunk_count"
                                ] = chunk_count
                                text = result["text"]

                                # æ£€æŸ¥æ˜¯å¦å¤„äºç¼“å†²çŠ¶æ€ï¼ˆLLMåå¤„ç†å™¨æ­£åœ¨ç´¯ç§¯æ–‡æœ¬ï¼‰
                                buffering = result.get("buffering", False)
                                llm_optimized = result.get("llm_optimized", False)

                                # åªæœ‰éç¼“å†²çŠ¶æ€çš„ç»“æœæ‰æ˜¯å®Œæ•´çš„ã€å¯ä»¥è¾“å‡ºçš„
                                should_output = not buffering

                                # æ„å»ºæ—¥å¿—ä¿¡æ¯
                                log_parts = [
                                    f"[{session_id}] {'[ç¼“å†²ä¸­]' if buffering else 'âœ“'} è¯†åˆ«æ–‡æœ¬[{chunk_count}]: {text}"
                                ]
                                if llm_optimized:
                                    log_parts.append(f"[LLMä¼˜åŒ–]")
                                if result.get("speaker_id"):
                                    log_parts.append(f"[è¯´è¯äºº:{result['speaker_id']}]")
                                if result.get("emotion"):
                                    log_parts.append(f"[æƒ…æ„Ÿ:{result['emotion']}]")
                                print(" ".join(log_parts))

                                # å‘é€è¯†åˆ«ç»“æœï¼ˆåŒ…å«ç¼“å†²çŠ¶æ€å’Œè¾“å‡ºæ ‡å¿—ï¼‰
                                response = {
                                    "type": "result",
                                    "text": text,
                                    "is_final": result.get("is_final", False),
                                    "chunk_number": chunk_count,
                                    "timestamp": result.get("timestamp"),
                                    "session_id": session_id,
                                    "buffering": buffering,  # æ˜¯å¦æ­£åœ¨ç¼“å†²
                                    "should_output": should_output,  # æ˜¯å¦åº”è¯¥è¾“å‡ºç»™ç”¨æˆ·
                                    "llm_optimized": llm_optimized,  # æ˜¯å¦ç»è¿‡LLMä¼˜åŒ–
                                }

                                # æ·»åŠ è¯´è¯äººä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                                if result.get("speaker_id") is not None:
                                    response["speaker_id"] = result["speaker_id"]

                                # æ·»åŠ æƒ…æ„Ÿä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                                if result.get("emotion") is not None:
                                    response["emotion"] = result["emotion"]

                                # æ·»åŠ VADä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                                if result.get("is_speech") is not None:
                                    response["is_speech"] = result["is_speech"]

                                await websocket.send_json(response)
                            else:
                                pass  # print(f"[{session_id}] è¯†åˆ«ç»“æœä¸ºç©º(å¯èƒ½æ˜¯é™éŸ³æ®µ)")

                        except Exception as e:
                            print(f"[{session_id}] ASRè¯†åˆ«é”™è¯¯: {e}")
                            import traceback

                            traceback.print_exc()
                            await websocket.send_json(
                                {"type": "error", "message": f"è¯†åˆ«é”™è¯¯: {str(e)}"}
                            )

                except Exception as e:
                    print(f"[{session_id}] å¤„ç†éŸ³é¢‘æ•°æ®å¤±è´¥: {e}")
                    import traceback

                    traceback.print_exc()
                    await websocket.send_json(
                        {
                            "type": "error",
                            "message": f"å¤„ç†éŸ³é¢‘æ•°æ®å¤±è´¥: {str(e)}",
                            "session_id": session_id,
                        }
                    )

    except WebSocketDisconnect:
        print(f"[{session_id}] WebSocketå®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
    except Exception as e:
        print(f"[{session_id}] WebSocketé”™è¯¯: {e}")
        import traceback

        traceback.print_exc()
        try:
            await websocket.send_json(
                {"type": "error", "message": f"è¿æ¥é”™è¯¯: {str(e)}"}
            )
        except:
            pass
    finally:
        # æ¸…ç†è¿æ¥è®°å½•
        with connection_lock:
            if session_id in active_connections:
                session_info = active_connections[session_id]
                duration = (datetime.now() - session_info["start_time"]).total_seconds()
                print(
                    f"[{session_id}] ä¼šè¯ç»“æŸ: æ—¶é•¿={duration:.1f}ç§’, å¤„ç†å—æ•°={session_info['chunk_count']}"
                )
                del active_connections[session_id]
                print(f"å½“å‰æ´»è·ƒè¿æ¥æ•°: {len(active_connections)}")

        try:
            await websocket.close()
        except:
            pass


# ========== é…ç½® Starlette åº”ç”¨ï¼ˆç”¨äº uvicornï¼‰ ==========
# ä½¿ç”¨ Streamable HTTP ä¼ è¾“ï¼ˆæ¨èï¼Œæ€§èƒ½æ›´å¥½ï¼‰ï¼Œå¹¶æ·»åŠ  CORS æ”¯æŒ
app = mcp.http_app(transport="streamable-http", middleware=cors_middleware)

# æ·»åŠ è‡ªå®šä¹‰è·¯ç”±åˆ° MCP åº”ç”¨
app.add_route("/upload-audio", upload_audio_endpoint, methods=["POST"])
app.add_websocket_route("/ws/realtime", websocket_realtime_endpoint)


# æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.route("/health")
async def health_check(request: Request):
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼Œç”¨äºç¡®è®¤æœåŠ¡å™¨æ­£å¸¸è¿è¡Œ"""
    return JSONResponse(
        {
            "status": "healthy",
            "service": "FunASR MCP Server",
            "timestamp": str(asyncio.get_event_loop().time()),
            "active_connections": len(active_connections),
        }
    )


# æ·»åŠ è¿æ¥çŠ¶æ€æŸ¥è¯¢ç«¯ç‚¹
@app.route("/connections")
async def connections_status(request: Request):
    """æŸ¥è¯¢å½“å‰æ´»è·ƒè¿æ¥çŠ¶æ€"""
    with connection_lock:
        connections_info = []
        for session_id, info in active_connections.items():
            duration = (datetime.now() - info["start_time"]).total_seconds()
            connections_info.append(
                {
                    "session_id": session_id,
                    "duration_seconds": round(duration, 1),
                    "chunk_count": info["chunk_count"],
                    "start_time": info["start_time"].isoformat(),
                }
            )

        return JSONResponse(
            {
                "total_connections": len(active_connections),
                "connections": connections_info,
            }
        )


# ========== å¯åŠ¨ä¿¡æ¯ ==========
if __name__ == "__main__":
    import uvicorn

    print("æ­£åœ¨å¯åŠ¨FunASR MCPæœåŠ¡å™¨ v3.0.0 (AIå¢å¼ºç‰ˆ)...")
    print(f"æœåŠ¡å™¨åœ°å€: http://0.0.0.0:{Config.SERVER_PORT}")
    print(f"MCPç«¯ç‚¹: http://0.0.0.0:{Config.SERVER_PORT}/mcp")
    print("\nå·²åŠ è½½æ¨¡å‹:")
    print(f"  ASRæ‰¹é‡: {Config.BATCH_MODEL}")
    print(
        f"  ASRæµå¼: {Config.REALTIME_MODEL} ({Config.REALTIME_CHUNK_SIZE[1]*60}mså»¶è¿Ÿ)"
    )
    print(f"  VAD: {Config.BATCH_VAD_MODEL}")
    print(f"  æ ‡ç‚¹: {Config.BATCH_PUNC_MODEL or 'æœªå¯ç”¨'}")
    print(f"  è¯´è¯äºº: {Config.BATCH_SPK_MODEL or 'æœªå¯ç”¨'}")
    print(f"  LLMåå¤„ç†: GGUFæ¨¡å‹ (è‡ªåŠ¨æ£€æµ‹GPU/CPU)")
    print(f"  è®¡ç®—è®¾å¤‡: {detect_device().upper()} (è‡ªåŠ¨æ£€æµ‹)")
    print("\nå¯ç”¨åŠŸèƒ½:")
    print("ã€€âœ“ æ‰¹é‡è¯­éŸ³è¯†åˆ« (VADåˆ†æ®µ+æ‰¹é‡ASR)")
    print("ã€€âœ“ å®æ—¶è¯­éŸ³è¯†åˆ« (WebSocketæµå¼ï¼ŒParaformer-Streaming)")
    print("  âœ“ LLMæµå¼åå¤„ç† (GGUFé‡åŒ–æ¨¡å‹ï¼Œè‡ªåŠ¨GPU/CPU)")
    print("  âœ“ æ ‡ç‚¹ç¬¦å·æ¢å¤")
    print("  âœ“ è¯´è¯äººåˆ†ç¦»")
    print("  âœ“ å¤šå®¢æˆ·ç«¯å¹¶å‘æ”¯æŒ")
    print("  âœ“ éŸ³é¢‘æ–‡ä»¶éªŒè¯")
    print("  âœ“ æµè§ˆå™¨å½•éŸ³ä¸Šä¼ è¯†åˆ«")
    print("\nWebSocketç«¯ç‚¹:")
    print(f"  ws://0.0.0.0:{Config.SERVER_PORT}/ws/realtime (Paraformeræµå¼è¯†åˆ«)")
    print("\nç›‘æ§ç«¯ç‚¹:")
    print(f"  http://0.0.0.0:{Config.SERVER_PORT}/health - å¥åº·æ£€æŸ¥")
    print(f"  http://0.0.0.0:{Config.SERVER_PORT}/connections - æ´»è·ƒè¿æ¥çŠ¶æ€")
    print("\nä½¿ç”¨ uvicorn å¯åŠ¨æœåŠ¡å™¨...")
    print("æç¤º: ç”Ÿäº§ç¯å¢ƒå¯ä½¿ç”¨å¤šè¿›ç¨‹:")
    print(f"  uvicorn main:app --host 0.0.0.0 --port {Config.SERVER_PORT} --workers 4")
    print("")

    # ä½¿ç”¨ uvicorn å¯åŠ¨æœåŠ¡å™¨ï¼ˆå¢åŠ è¶…æ—¶é…ç½®ä»¥æ”¯æŒé•¿è¿æ¥ï¼‰
    uvicorn.run(
        app,
        host=Config.SERVER_HOST,
        port=Config.SERVER_PORT,
        timeout_keep_alive=75,  # Keep-alive è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        timeout_graceful_shutdown=30,  # ä¼˜é›…å…³é—­è¶…æ—¶
    )
